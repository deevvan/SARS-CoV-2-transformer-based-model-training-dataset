{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae08ac14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Statistics:\n",
      "Total Sequences: 1660854\n",
      "Total Bases: 1114385340\n",
      "Minimum Length: 0 bases\n",
      "Maximum Length: 1600 bases\n",
      "Average Length: 670.97 bases\n"
     ]
    }
   ],
   "source": [
    "# Python script to count sequence length statistics for trimmed RBD sequences\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "def generate_sequence_statistics(fasta_file):\n",
    "    sequence_lengths = []\n",
    "    total_sequences = 0\n",
    "    total_bases = 0\n",
    "\n",
    "    with open(fasta_file, \"r\") as handle:\n",
    "        for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            total_sequences += 1\n",
    "            sequence_length = len(record.seq)\n",
    "            sequence_lengths.append(sequence_length)\n",
    "            total_bases += sequence_length\n",
    "\n",
    "    # Calculate statistics\n",
    "    min_length = min(sequence_lengths)\n",
    "    max_length = max(sequence_lengths)\n",
    "    average_length = total_bases / total_sequences\n",
    "\n",
    "    # Print the statistics\n",
    "    print(\"Sequence Statistics:\")\n",
    "    print(f\"Total Sequences: {total_sequences}\")\n",
    "    print(f\"Total Bases: {total_bases}\")\n",
    "    print(f\"Minimum Length: {min_length} bases\")\n",
    "    print(f\"Maximum Length: {max_length} bases\")\n",
    "    print(f\"Average Length: {average_length:.2f} bases\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fasta_file = \"your/path/msaCodon_1024_trimmed_RBD_new.fasta\"  # Replace with your FASTA file\n",
    "    generate_sequence_statistics(fasta_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "033f9df8-4e7c-44dd-83a2-7cca51dc53e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences between lengths 671 and 671 written to '/mmfs1/projects/changhui.yan/DeewanB/gisaid_data/main_MSA_files/filtered_msaCodon_1024_trimmed_RBD_new.fasta'.\n"
     ]
    }
   ],
   "source": [
    "# Python script to calculate first quartile (Q1), third quartile (Q3), and the interquartile range (IQR) and \n",
    "# use the IQR to determine the lower and upper bounds for outlier detection and remove \"OUTLIER\" readlengths.\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def count_sequence_lengths(fasta_file):\n",
    "    sequence_lengths = []\n",
    "    sequences = []\n",
    "\n",
    "    with open(fasta_file, \"r\") as file:\n",
    "        sequence = \"\"\n",
    "        header = \"\"\n",
    "\n",
    "        for line in file:\n",
    "            if line.startswith(\">\"):\n",
    "                if sequence:\n",
    "                    sequence_lengths.append(len(sequence))\n",
    "                    sequences.append((header, sequence))\n",
    "                header = line.strip()\n",
    "                sequence = \"\"\n",
    "            else:\n",
    "                sequence += line.strip()\n",
    "\n",
    "        # Don't forget to count the last sequence\n",
    "        if sequence:\n",
    "            sequence_lengths.append(len(sequence))\n",
    "            sequences.append((header, sequence))\n",
    "\n",
    "    return sequence_lengths, sequences\n",
    "\n",
    "def calculate_iqr_outliers(sequence_lengths):\n",
    "    q1 = np.percentile(sequence_lengths, 25)\n",
    "    q3 = np.percentile(sequence_lengths, 75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "def filter_outliers_and_write(sequences, lower_bound, upper_bound, output_file):\n",
    "    with open(output_file, \"w\") as outfile:\n",
    "        for header, sequence in sequences:\n",
    "            if lower_bound <= len(sequence) <= upper_bound:\n",
    "                outfile.write(f\"{header}\\n{sequence}\\n\")\n",
    "\n",
    "def main():\n",
    "    fasta_file = \"your/path/msaCodon_1024_trimmed_RBD_new.fasta\"\n",
    "    output_file = \"your/path/filtered_msaCodon_1024_trimmed_RBD_new.fasta\"\n",
    "\n",
    "    sequence_lengths, sequences = count_sequence_lengths(fasta_file)\n",
    "    lower_bound, upper_bound = calculate_iqr_outliers(sequence_lengths)\n",
    "    filter_outliers_and_write(sequences, lower_bound, upper_bound, output_file)\n",
    "\n",
    "    print(f\"Sequences between lengths {int(lower_bound)} and {int(upper_bound)} written to '{output_file}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c5c1f57-d0f3-42c5-b1b0-ed9d6c1dd888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Statistics:\n",
      "Total Sequences: 1659465\n",
      "Total Bases: 1113501015\n",
      "Minimum Length: 671 bases\n",
      "Maximum Length: 671 bases\n",
      "Average Length: 671.00 bases\n"
     ]
    }
   ],
   "source": [
    "# Python script to count sequence statistics for trimmed RBD sequences with outliers removed\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "def generate_sequence_statistics(fasta_file):\n",
    "    sequence_lengths = []\n",
    "    total_sequences = 0\n",
    "    total_bases = 0\n",
    "\n",
    "    with open(fasta_file, \"r\") as handle:\n",
    "        for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            total_sequences += 1\n",
    "            sequence_length = len(record.seq)\n",
    "            sequence_lengths.append(sequence_length)\n",
    "            total_bases += sequence_length\n",
    "\n",
    "    # Calculate statistics\n",
    "    min_length = min(sequence_lengths)\n",
    "    max_length = max(sequence_lengths)\n",
    "    average_length = total_bases / total_sequences\n",
    "\n",
    "    # Print the statistics\n",
    "    print(\"Sequence Statistics:\")\n",
    "    print(f\"Total Sequences: {total_sequences}\")\n",
    "    print(f\"Total Bases: {total_bases}\")\n",
    "    print(f\"Minimum Length: {min_length} bases\")\n",
    "    print(f\"Maximum Length: {max_length} bases\")\n",
    "    print(f\"Average Length: {average_length:.2f} bases\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fasta_file = \"your/path/filtered_msaCodon_1024_trimmed_RBD_new.fasta\"  # Replace with your FASTA file\n",
    "    generate_sequence_statistics(fasta_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44caba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Python script to make a subset of the filtered_msaCodon_1024_trimmed_RBD.fasta without N \n",
    "\n",
    "from Bio import SeqIO\n",
    "import random\n",
    "\n",
    "# Input FASTA file and output file\n",
    "input_fasta = \"your/path/filtered_msaCodon_1024_trimmed_RBD_new.fasta\"\n",
    "output_fasta = \"your/path/filtered_msaCodon_1024_trimmed_RBD_new_1_6mil.fasta\"\n",
    "\n",
    "# Read all sequences from the input FASTA file\n",
    "all_sequences = list(SeqIO.parse(input_fasta, \"fasta\"))\n",
    "\n",
    "# Randomly select 1 million sequences\n",
    "num_sequences_to_select = 1600000\n",
    "subset_sequences = random.sample(all_sequences, min(num_sequences_to_select, len(all_sequences)))\n",
    "\n",
    "# Filter sequences to contain only A, T, G, and C, and have lengths as multiples of 3\n",
    "valid_sequences = [seq for seq in subset_sequences if set(str(seq.seq)).issubset(\"ATGC\")]\n",
    "\n",
    "# Ensure each selected sequence length is a multiple of 3 or remove 1 or 2 nucleotides\n",
    "for i in range(len(valid_sequences)):\n",
    "    seq_len = len(valid_sequences[i])\n",
    "    if seq_len % 3 != 0:\n",
    "        trim_length = seq_len % 3\n",
    "        valid_sequences[i] = valid_sequences[i][:-trim_length]\n",
    "\n",
    "# Write the selected sequences to the output FASTA file\n",
    "with open(output_fasta, \"w\") as output_handle:\n",
    "    SeqIO.write(valid_sequences, output_handle, \"fasta\")\n",
    "\n",
    "print(f\"Randomly selected {num_sequences_to_select} valid sequences and saved to {output_fasta}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51e64b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Statistics:\n",
      "Total Sequences: 1600000\n",
      "Total Bases: 1070400000\n",
      "Minimum Length: 669 bases\n",
      "Maximum Length: 669 bases\n",
      "Average Length: 669.00 bases\n"
     ]
    }
   ],
   "source": [
    "# Python script to count sequence statistics for valid 1.6 million trimmed RBD sequences \n",
    "from Bio import SeqIO\n",
    "\n",
    "def generate_sequence_statistics(fasta_file):\n",
    "    sequence_lengths = []\n",
    "    total_sequences = 0\n",
    "    total_bases = 0\n",
    "\n",
    "    with open(fasta_file, \"r\") as handle:\n",
    "        for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            total_sequences += 1\n",
    "            sequence_length = len(record.seq)\n",
    "            sequence_lengths.append(sequence_length)\n",
    "            total_bases += sequence_length\n",
    "\n",
    "    # Calculate statistics\n",
    "    min_length = min(sequence_lengths)\n",
    "    max_length = max(sequence_lengths)\n",
    "    average_length = total_bases / total_sequences\n",
    "\n",
    "    # Print the statistics\n",
    "    print(\"Sequence Statistics:\")\n",
    "    print(f\"Total Sequences: {total_sequences}\")\n",
    "    print(f\"Total Bases: {total_bases}\")\n",
    "    print(f\"Minimum Length: {min_length} bases\")\n",
    "    print(f\"Maximum Length: {max_length} bases\")\n",
    "    print(f\"Average Length: {average_length:.2f} bases\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fasta_file = \"your/path/filtered_msaCodon_1024_trimmed_RBD_new_1_6mil.fasta\"  # Replace with your FASTA file\n",
    "    generate_sequence_statistics(fasta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7770759a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences: 100%|██████████| 1600000/1600000 [15:45:45<00:00, 28.20it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches found: 1599926\n",
      "Total sequences: 1600000\n",
      "Output CSV file saved as /mmfs1/projects/changhui.yan/DeewanB/gisaid_data/main_MSA_files/filtered_msaCodon_1024_trimmed_RBD_new_1_6mil.csv\n"
     ]
    }
   ],
   "source": [
    "# Python script to write out matching fasta files with Accession ID values in metadata file to csv \n",
    "# files with Variant values and convert each nucleotide sequence to protein sequences\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count, Manager\n",
    "\n",
    "# Load your metadata DataFrame (df_metadata) and provide the correct path to your FASTA file and \"RBD.voc.json\" file.\n",
    "csv_file = \"your/path/metadata.tsv\"\n",
    "df_metadata = pd.read_csv(csv_file, sep='\\t', dtype=str, low_memory=False, encoding='latin-1')\n",
    "\n",
    "# Load the voc.json file\n",
    "with open('your/path/voc.json', 'r') as json_file:\n",
    "    voc_data = json.load(json_file)\n",
    "\n",
    "# Define a function to determine the VOC value based on Pango Lineage\n",
    "def determine_voc(lineage):\n",
    "    for voc, lineages in voc_data.items():\n",
    "        if lineage in lineages:\n",
    "            return voc\n",
    "    return \"nonVOC\"\n",
    "\n",
    "# Define the translation function\n",
    "def translate_nucleotides_to_protein(nucleotide_sequence):\n",
    "    return str(Seq(nucleotide_sequence).translate())\n",
    "\n",
    "# Define the output CSV file\n",
    "output_csv_file = \"your/path/filtered_msaCodon_1024_trimmed_RBD_new_1_6mil.csv\"\n",
    "\n",
    "# Initialize a count for matches\n",
    "match_count = 0\n",
    "total_sequences = 0\n",
    "\n",
    "# Function to process each sequence\n",
    "def process_sequence(record):\n",
    "    global df_metadata, voc_data\n",
    "    accession_id_fasta = record.description.split(\"|\")[1]\n",
    "    sequence = str(record.seq)\n",
    "\n",
    "    # Check if the Accession ID is present in the metadata DataFrame\n",
    "    match_row = df_metadata[df_metadata['Accession ID'] == accession_id_fasta]\n",
    "    if not match_row.empty:\n",
    "        lineage = match_row['Pango lineage'].values[0]\n",
    "\n",
    "        # Create a dictionary for the current record\n",
    "        output_data = {\n",
    "            'Accession ID': accession_id_fasta,\n",
    "            'Lineage': lineage,\n",
    "            'RBD nucleotide': sequence,\n",
    "            'Variant': determine_voc(lineage),\n",
    "            'RBD protein': translate_nucleotides_to_protein(sequence),  # Using Biopython's translate_nucleotides_to_protein function to convert RBD nucleotide sequences to RBD protein sequences\n",
    "        }\n",
    "        return output_data\n",
    "    return None\n",
    "\n",
    "# Write the header to the output CSV file\n",
    "with open(output_csv_file, 'w', newline='') as f:\n",
    "    writer = pd.DataFrame(columns=['Accession ID', 'Lineage', 'RBD nucleotide', 'Variant', 'RBD protein'])\n",
    "    writer.to_csv(f, index=False)\n",
    "\n",
    "# Estimate the total number of sequences for tqdm\n",
    "with open(\"your/path/filtered_msaCodon_1024_trimmed_RBD_new_1_6mil.fasta\", \"r\") as fasta_file:\n",
    "    total_sequences_estimated = sum(1 for line in fasta_file if line.startswith(\">\"))\n",
    "\n",
    "# Process sequences using multiprocessing Pool\n",
    "with Pool(processes = 32) as pool, tqdm(total=total_sequences_estimated, desc=\"Processing sequences\") as pbar:\n",
    "    for result in pool.imap(process_sequence, SeqIO.parse(\"your/path/filtered_msaCodon_1024_trimmed_RBD_new_1_6mil.fasta\", \"fasta\")):\n",
    "        pbar.update()\n",
    "        if result:\n",
    "            with open(output_csv_file, 'a', newline='') as f:\n",
    "                output_df = pd.DataFrame([result])\n",
    "                output_df.to_csv(f, mode='a', header=False, index=False)\n",
    "                match_count += 1\n",
    "\n",
    "# Print the results\n",
    "print(f\"Matches found: {match_count}\")\n",
    "print(f\"Total sequences: {total_sequences_estimated}\")\n",
    "print(f\"Output CSV file saved as {output_csv_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
